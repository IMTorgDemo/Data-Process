{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generalizing the Machine Learning Process\n",
    "Date: 2019-05-09  \n",
    "Author: Jason Beach  \n",
    "Categories: Process, DataScience  \n",
    "Tags: machine-learning, best-practice   \n",
    "<!--eofm-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This work describes a general approach to follow when performing machine learning (ML) manually, and when automating in a deployment setting.  Unlike a classical statistical analysis, standard machine learning projects typically follow a general and repeatable process.  While the practictioner should be aware of details for each of the steps and the reasons for choosing them, there is much less design-thinking and checking of assumptions that are necessary components of more mathematical modeling fields.  This makes the machine learning process amenable to deployment as a service because automating the re-training and prediction of a model with consistent data is straight-forward programming."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Theory\n",
    "\n",
    "Most of the design-thinking in the ML process is in choosing a variety of models for comparing performance against.  The following three characteristics succinctly describe a ML model.  See [here]( {{< ref \"/posts/blog_page-todo.md\" >}}) for more explanation.\n",
    "\n",
    "1. Representation: structural model characteristics\n",
    "    - name\n",
    "    - family\n",
    "    - interpretability\n",
    "    - type \n",
    "        + generative / discriminative \n",
    "        + bias / var\n",
    "        + fixed- / variable- learner\n",
    "2. Evaluation: functions applied to the structure\n",
    "    - objective\n",
    "    - cost\n",
    "    - loss\n",
    "3. Optimization: algorithms necessary to solve for parameters\n",
    "\n",
    "It is also important to understand how the chosen model effects the modeling process\n",
    "\n",
    "- assumptions inherent in representation\n",
    "- alignment of loss function with project goals\n",
    "- sources of bias / variance\n",
    "- determination of resource constraints\n",
    "- enumeration of how over-tuning can occur (regularization)\n",
    "- understanding when manual methods are ineffective 'fiddling' of model implementation parameters\n",
    "- statement of strong false assumptions can be better than weak true ones, because they need more data\n",
    "\n",
    "_Note:_ This should be considered carefully with feature engineering and feature selection to ensure the input transformations align with the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Machine Learning Process\n",
    "\n",
    "The following are the general steps taken in the ML Process.  They are similar to many other problem-solving processes, but tailored to ML specifics.  There are a few steps where care should be taken to ensure the process is reasonable.  These are more design-oriented and some research may be necessary depending on the scenario.  \n",
    "\n",
    "The practicioner must ensure he is maintaining honesty with the investigation.  One important check is laying-out proper evaluation methods, before implementing them.  This is similar to classical statistics in choosing an accepatable p-value before running the model.  They include selecting evaluation scores and how they should be evaluated.  Another check is on model resource and time requirements.  More sophisticated models need more memory to implement and take a longer time to run.  These are highly dependent on the environment they are deployed to.  These should be determined with the customer, at the beginning.  To learn more read, [here]( {{< ref \"/posts/blog_page-todo.md\" >}}) for more. \n",
    "\n",
    "The categories to be predicted on, and the percent of records used for each in training, is a very important subject.  If your target data is of a much lower percentage amount than the rest (needle-in-haystack / imbalanced data problem), then it should be addressed before separating training and testing data.  The most orthodox and direct way to deal with this problem is to simply resample from the target records, with replacement, for enough times to reach 50% of your data.  However, this is an important area of research and some time should be taken before moving forward in the process.  For more information on imbalanced data, check [here]( {{< ref \"/posts/blog_page-todo.md\" >}}).\n",
    "\n",
    "While classical statistics places a strong emphasis on model exploration and ensuring assumptions are met, this is less important in ML.  Instead, much more time should be focused on the features used in the model.  This is mainly in the form of Feature Engineering, which can include several different methodologies, such as Feature Extraction, Feature Selection / Dimensionality Reduction, and Feature Engineering.  Read more about this, [here]( {{< ref \"/posts/blog_page-todo.md\" >}}).  \n",
    "\n",
    "_Discover_\n",
    "\n",
    "* determine problem and constraints\n",
    "* determine characteristics the problem / scenario dictates on the solution\n",
    "    - model family\n",
    "    - acceptable methods of dimensionality reduction and regularization\n",
    "    - deployment environment\n",
    "* decide evaluation\n",
    "    - primary / secondary evaluation score (ie. accuracy)\n",
    "    - methods of evaluation (ie. confusion matrix, roc)\n",
    "\n",
    "\n",
    "_Collect and Transform_\n",
    "\n",
    "* obtain raw data \n",
    "    - internal data warehouses\n",
    "    - external APIs and services\n",
    "* integration and cleaning\t\n",
    "* filter, aggregate, and query\n",
    "\n",
    "\n",
    "_Summary and Process_\n",
    "\n",
    "* exploration\n",
    "* preparation\n",
    "     - address balance (classification, anova, etc.)\n",
    "     - create Train, Validate, Test with split (above)\n",
    "* configure Feature Extraction with feature_union\n",
    "* configure Preprocess and choose model-families with pipeline\n",
    "\n",
    "\n",
    "_Build_\n",
    "\n",
    "* train the models\n",
    "    - apply k-folds CV and grid search with Training set\n",
    "    - perform on multiple model-families and hyper-parameters\n",
    "* evaluate models\n",
    "    - review afore-mentioned confusion matrix, scoring, classifier-threshold, and tests\n",
    "    - select the best model-family / hyper-parameters\n",
    "    - apply to Validation set or all of Training set to model-family to parameterize it and set as the final model\n",
    "* refine performance\n",
    "    - debug performance with learning curve, lift chart\n",
    "    - use Testing set to evaluate final model characteristics\n",
    "    - export to binary file\n",
    "\n",
    "\n",
    "_Deliver_\n",
    "\n",
    "* select solution\n",
    "    - design interface most appropriate for using the model\n",
    "    - automate data integration and pipelines\n",
    "    - implement model in deployable environment\n",
    "* deploy solution within system environments\n",
    "\n",
    "\n",
    "_Note:_ Train, Validate, and Test should be from different (independent) data sets, if possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stakeholder Interaction and Timeline\n",
    "\n",
    "It is useful to display these in relation to interactions that must take place with stakeholders.  These may be business users who need a problem solved, or technology departments that will have to support applications that implement the solution.  The y-axis show stage proximity to these stakeholders.\n",
    "\n",
    "While every project is different, most stages use a similar proportion of time.  The horizontal axis lays-out the timeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![machine learning process](images/ml_process.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstation\n",
    "\n",
    "The following code demonstrates the programming portions of these stages and steps using a toy example on a simulated diverse dataset of both numeric and categorical data.  It separates the columns and uses transform pipelines to perform different dimensionality reduction techniques.[^1] This does display the important steps that must be taken with stakeholders. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook configurations for the kernel and display output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_rows', 10)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide for utility functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "\n",
    "def randomString(stringLength=10):\n",
    "    \"\"\"Generate a random string of fixed length \"\"\"\n",
    "    letters = string.ascii_lowercase\n",
    "    return ''.join(random.choice(letters) for i in range(stringLength))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While importing modules, try to organize them in the order they are used, and by their parent library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import learning_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect and transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bring internal and external data, together, for a combined and succinct dataset.  Here, we are simulating both categorical and numeric data for the same dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make data (both numeric and categorical)\n",
    "iCOLUMNS = 50\n",
    "iROWS = 1000\n",
    "#generate classification dataset\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "X_cat, Y_cat = make_blobs(n_samples=iROWS, centers=2, n_features=iCOLUMNS, random_state=1)\n",
    "categories = [randomString(5) for x in range(5)]\n",
    "cols = [random.choices(categories, k=iCOLUMNS) for _ in range(iROWS)]\n",
    "X_cat = np.array(cols)\n",
    "\n",
    "\n",
    "#generate regression dataset\n",
    "from sklearn.datasets.samples_generator import make_regression\n",
    "X_num, not_used = make_regression(n_samples=iROWS, n_features=iCOLUMNS, noise=0.1, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your processing is simplified when most of your work is within a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set in dataframe\n",
    "dfX_cat = pd.DataFrame(X_cat, columns=['IndepCat-'+str(x) for x in range(iCOLUMNS)] )\n",
    "dfX_num = pd.DataFrame(X_num, columns=['IndepNum-'+str(x) for x in range(iCOLUMNS)])\n",
    "dfY_cat = pd.DataFrame(Y_cat, columns=[\"Dep\"])\n",
    "dfData = pd.concat([dfY_cat, dfX_cat, dfX_num], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary and process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode your data with transformations in an appropriate order.  Remember that some transformations, such as scaling, should be performed after separation of testing and training datasets because you will be dividing all records by the maximum value, within the dataset.  In model implementation, you would not see the maximum value of your original testing dataset; rather, you would use the current dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training records: 800\n",
      "Testing records: 200\n"
     ]
    }
   ],
   "source": [
    "#separate\n",
    "X = dfData.drop('Dep', axis=1)\n",
    "y = dfData['Dep']\n",
    "\n",
    "#encode y and create datasets\n",
    "enc = LabelEncoder()\n",
    "y_set = enc.fit_transform(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_set, test_size=0.2)\n",
    "\n",
    "print( \"Training records: %s\"%(X_train.shape[0]) )\n",
    "print( \"Testing records: %s\"%(X_test.shape[0]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, you perform scaling, imputation, Principal Component Analysis (PCA), and other transformations whose arguments are dependent upon the same dataset.\n",
    "\n",
    "Also, the transformation pipelines should be divided into numeric and categoric because some transformations, such as PCA, are inappropriate for categoric data.  Instead use methods, such as _Select K Best_, for dimensionality reduction.\n",
    "\n",
    "Working with pipelines can be unwieldly at some times.  For a reference of pipelines, see [sklearn docs](https://scikit-learn.org/stable/modules/compose.html#pipelines-and-composite-estimators)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create feature union of numeric data\n",
    "features = []\n",
    "features.append(('pca', PCA()))                    #<<<GRID\n",
    "features.append(('select_best', SelectKBest()))    #<<<GRID\n",
    "num_feature_eng = FeatureUnion(features)\n",
    "\n",
    "#create the preprocessing pipelines for both numeric and categorical data\n",
    "numeric_features = [x for x in X_train.columns if x.split('-')[0]=='IndepNum' ]\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('num_feature_eng', num_feature_eng)\n",
    "])\n",
    "\n",
    "categorical_features =  [x for x in X_train.columns if x.split('-')[0]=='IndepCat' ]\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore')),\n",
    "    ('select_best', SelectKBest(k=6))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "#append classifier to preprocessing pipeline\n",
    "#full prediction pipeline\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', LogisticRegression(solver='lbfgs'))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimize your hyper-parameters in a grid search.  You may have to get output for all the pipeline keys to find their names because the notation can become quite lenthy based on the amount of nesting, such as this pipeline displays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'preprocessor__num__imputer__strategy': ['mean', 'median'],\n",
    "    'classifier__C': [0.1, 1.0, 10, 100],\n",
    "    'preprocessor__num__num_feature_eng__pca__n_components': [.75, .80, .85, .90, .95],\n",
    "    'preprocessor__num__num_feature_eng__select_best__k': [5, 7, 9, 11]\n",
    "}\n",
    "gridClf = GridSearchCV(clf, param_grid, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build your model through optimizing values over the grid.  This is usually based on stochastic gradient descent, or some other iterative routine.  Convergence may be time-consuming depending on the model you've chosen and the number of parameters and hyper-parameters that must be selected.  NaiveBayes methods can be some of the most costly.  Run more balanced models, first, to get an idea of the parameter space, before trying more costly approaches.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('preprocessor', ColumnTransformer(n_jobs=None, remainder='drop', sparse_threshold=0.3,\n",
       "         transformer_weights=None,\n",
       "         transformers=[('num', Pipeline(memory=None,\n",
       "     steps=[('imputer', SimpleImputer(copy=True, fill_value=None, missing_values=nan,\n",
       "       strategy='median', verbo...enalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'preprocessor__num__imputer__strategy': ['mean', 'median'], 'classifier__C': [0.1, 1.0, 10, 100], 'preprocessor__num__num_feature_eng__pca__n_components': [0.75, 0.8, 0.85, 0.9, 0.95], 'preprocessor__num__num_feature_eng__select_best__k': [5, 7, 9, 11]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridClf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take the _best_ model with parameters / hyper-parameters from highest grid-search, cross-validation, and apply it to the test data.  This data is simulated and you should be able to perform better than a coin-flip (50%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best logistic regression from grid search: 0.515\n"
     ]
    }
   ],
   "source": [
    "print((\"best logistic regression from grid search: %.3f\"\n",
    "       % gridClf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get an idea of the results and parameter space.  Extreme values may indicate over-fitting or some other anomaly is occuring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: (CV score=0.484)\n",
      "\n",
      "\n",
      "Best Parameters\n",
      " {'classifier__C': 10, 'preprocessor__num__imputer__strategy': 'mean', 'preprocessor__num__num_feature_eng__pca__n_components': 0.9, 'preprocessor__num__num_feature_eng__select_best__k': 5}\n",
      "\n",
      "\n",
      "Best Estimator\n",
      " Pipeline(memory=None,\n",
      "     steps=[('preprocessor', ColumnTransformer(n_jobs=None, remainder='drop', sparse_threshold=0.3,\n",
      "         transformer_weights=None,\n",
      "         transformers=[('num', Pipeline(memory=None,\n",
      "     steps=[('imputer', SimpleImputer(copy=True, fill_value=None, missing_values=nan, strategy='mean',\n",
      "       verbose...enalty='l2', random_state=None, solver='lbfgs',\n",
      "          tol=0.0001, verbose=0, warm_start=False))])\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation\n",
    "#GridSearchCV: Mean cross-validated score of the best_estimator\n",
    "#SGDClassifier: Returns the mean accuracy on the given test data and labels\n",
    "print(\"Best Score: (CV score=%0.3f)\" % gridClf.best_score_)\n",
    "print(\"\\n\")\n",
    "print(\"Best Parameters\\n %s\" % gridClf.best_params_ )\n",
    "print(\"\\n\")\n",
    "print(\"Best Estimator\\n %s\" %  gridClf.best_estimator_ )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A confusion matrix is your basic display of results.  This is for your training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix: Training\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[255, 149],\n",
       "       [146, 250]])"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_train_pred = gridClf.predict(X_train)\n",
    "print( \"Confusion matrix: Training\")\n",
    "confusion_matrix(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This confusion matrix is for your test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix: Testing\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[51, 45],\n",
       "       [52, 52]])"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = gridClf.predict(X_test)\n",
    "print( \"Confusion matrix: Testing\")\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After getting a general feel for the situation, look at the specific performance metrics you set, at the beginning of your problem statement.  Ensure you hold yourself to this standard and do not change the solutions' needs based on current results.  For a complete listing of performance metrics, view the [sklearn docs](https://scikit-learn.org/stable/modules/model_evaluation.html#model-evaluation-quantifying-the-quality-of-predictions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training probability: 0.484\n",
      "Area Under ROC Curve: 0.492\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "\n",
    "#predictions for outcome labels\n",
    "#Predict class probabilities for X.  The predicted class probabilities of an input sample are computed as the mean predicted\n",
    "#class probabilities of the trees in the forest. The class probability of a single tree is the fraction of samples of the same\n",
    "#class in a leaf.\n",
    "y_class_prob = gridClf.predict_proba(X_test)                # called   predict_proba(), for some classifiers\n",
    "y_prob = np.asarray( [x[1] for x in y_class_prob], dtype=np.float32)\n",
    "threshold = 0                                               # set threshold\n",
    "y_some_digit_pred = (y_prob > threshold)\n",
    "print( \"Average training probability: %0.3f\" % np.mean(y_prob) )\n",
    "\n",
    "#roc auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print( \"Area Under ROC Curve: %0.3f\" % roc_auc_score(y_test, y_prob) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A variety of different plots can be used to explore model and result performance.  The ROC Curve is one of the most fundamental, but several others are of importance.  Performance graphs are explained in the [sklearn docs](https://scikit-learn.org/stable/modules/learning_curve.html#validation-curves-plotting-scores-to-evaluate-models). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "log_y_prob = gridClf.decision_function(X_test) \n",
    "\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#plt.figure(0).clf()\n",
    "\n",
    "#LogisticRegression  \n",
    "y_prob = log_y_prob\n",
    "fpr, tpr, thresh = metrics.roc_curve(y_test, y_prob)\n",
    "auc = metrics.roc_auc_score(y_test, y_prob)\n",
    "plt.plot(fpr,tpr,label=\"logistic reg, auc=\"+str(auc))\n",
    "\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deliver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model for future use, especially if you just spent a large amount of time getting the algorithm to converge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "import os\n",
    "\n",
    "cwd = os.getcwd()\n",
    "file_path = cwd+'/Data/project/Models/'\n",
    "\n",
    "#save the model to disk\n",
    "filename = file_path+'finalized_model.sav'\n",
    "joblib.dump(gridClf, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the model within the necessary solution system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in deployment application...\n",
    "#load the model from disk\n",
    "loaded_model = joblib.load(filename)\n",
    "result = loaded_model.score(X_test, Y_test)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this work, we provide an orthodox approach to the ML Process.  We list the stages involved and the steps for each, and align these with more traditional modeling and analysis processes.  Demo code runs through the basic ideas.  This code can be modified in order to automate processing in a separate environment, such as a deployed service.  The complete process can be generalized to many situations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[^1]: [Column Transformer with Mixed Types](https://scikit-learn.org/stable/auto_examples/compose/plot_column_transformer_mixed_types.html#sphx-glr-auto-examples-compose-plot-column-transformer-mixed-types-py)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
