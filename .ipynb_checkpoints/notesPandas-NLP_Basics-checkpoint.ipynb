{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "# Launch the installer to download \"gutenberg\" and \"stop words\" corpora.\n",
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt', 'bible-kjv.txt', 'blake-poems.txt', 'bryant-stories.txt', 'burgess-busterbrown.txt', 'carroll-alice.txt', 'chesterton-ball.txt', 'chesterton-brown.txt', 'chesterton-thursday.txt', 'edgeworth-parents.txt', 'melville-moby_dick.txt', 'milton-paradise.txt', 'shakespeare-caesar.txt', 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt', 'whitman-leaves.txt']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import gutenberg, stopwords\n",
    "print(gutenberg.fileids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw:\n",
      " [Alice's Adventures in Wonderland by Lewis Carroll 1865]\n",
      "\n",
      "CHAPTER I. Down the Rabbit-Hole\n",
      "\n",
      "Alice was\n"
     ]
    }
   ],
   "source": [
    "persuasion = gutenberg.raw('austen-persuasion.txt')\n",
    "alice = gutenberg.raw('carroll-alice.txt')\n",
    "print('Raw:\\n',alice[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Regex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "[regex cheatsheet](https://www.debuggex.com/cheatsheet/regex/python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title removed:\n",
      " \n",
      "\n",
      "CHAPTER I. Down the Rabbit-Hole\n",
      "\n",
      "Alice was beginning to get very tired of sitting by her sister on\n"
     ]
    }
   ],
   "source": [
    "pattern = \"[\\[].*?[\\]]\"\n",
    "persuasion = re.sub(pattern, \"\", persuasion)\n",
    "alice = re.sub(pattern, \"\", alice) \n",
    "print('Title removed:\\n', alice[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chapter headings removed:\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "Alice was beginning to get very tired of sitting by her sister on the\n",
      "bank, and of having nothin\n"
     ]
    }
   ],
   "source": [
    "persuasion = re.sub(r'Chapter \\d+', '', persuasion)\n",
    "alice = re.sub(r'CHAPTER .*', '', alice)\n",
    "print('Chapter headings removed:\\n', alice[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra whitespace removed:\n",
      " Alice was beginning to get very tired of sitting by her sister on the bank, and of having nothing to\n"
     ]
    }
   ],
   "source": [
    "persuasion = ' '.join(persuasion.split())\n",
    "alice = ' '.join(alice.split())\n",
    "print('Extra whitespace removed:\\n', alice[0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# SpaCy(thon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('english')[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "alice_doc = nlp(alice)\n",
    "persuasion_doc = nlp(persuasion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The alice_doc object is a <class 'spacy.tokens.doc.Doc'> object.\n",
      "It is 34420 tokens long\n",
      "The first three tokens are 'Alice was beginning'\n",
      "The type of each token is <class 'spacy.tokens.token.Token'>\n"
     ]
    }
   ],
   "source": [
    "print(\"The alice_doc object is a {} object.\".format(type(alice_doc)))\n",
    "print(\"It is {} tokens long\".format(len(alice_doc)))\n",
    "print(\"The first three tokens are '{}'\".format(alice_doc[:3]))\n",
    "print(\"The type of each token is {}\".format(type(alice_doc[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def word_freq(text, include_stop=True):\n",
    "    words = []\n",
    "    for token in text:\n",
    "        if not token.is_punct and (not token.is_stop or include_stop):\n",
    "            words.append(token.text)\n",
    "    return Counter(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "alice_freq = word_freq(alice_doc)\n",
    "persuasion_freq = word_freq(persuasion_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 1524),\n",
       " ('and', 796),\n",
       " ('to', 724),\n",
       " ('a', 611),\n",
       " ('I', 534),\n",
       " ('it', 524),\n",
       " ('she', 508),\n",
       " ('of', 499),\n",
       " ('said', 453),\n",
       " ('Alice', 394)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alice_freq.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "alice_freq = word_freq(alice_doc, include_stop=False).most_common(10)\n",
    "persuasion_freq = word_freq(persuasion_doc, include_stop=False).most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('said', 453),\n",
       " ('Alice', 394),\n",
       " (\"n't\", 205),\n",
       " (\"'s\", 190),\n",
       " ('little', 124),\n",
       " ('like', 84),\n",
       " ('know', 83),\n",
       " ('went', 83),\n",
       " ('thought', 74),\n",
       " ('Queen', 73)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alice_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "alice_common = [pair[0] for pair in alice_freq]\n",
    "persuasion_common = [pair[0] for pair in persuasion_freq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique to Alice:  {'went', \"n't\", 'thought', 'Alice', 'like', 'said', 'Queen', 'know'}\n",
      "Unique to Persuasion:  {'Mr', 'Mrs', 'good', 'Wentworth', 'Anne', 'Captain', 'Lady', 'Elliot'}\n"
     ]
    }
   ],
   "source": [
    "print('Unique to Alice: ', set(alice_common)-set(persuasion_common))\n",
    "print('Unique to Persuasion: ', set(persuasion_common)-set(alice_common))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def lemma_freq(text, include_stop=True):\n",
    "    lemmas = []\n",
    "    for token in text:\n",
    "        if not token.is_punct and (not token.is_stop or include_stop):\n",
    "            lemmas.append(token.lemma_)\n",
    "    return Counter(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alice_lemma_freq = lemma_freq(alice_doc, include_stop=False).most_common(10)\n",
    "persuasion_lemma_freq = lemma_freq(persuasion_doc, include_stop=False).most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = list(alice_doc.sents)\n",
    "example_sentence = sentences[2]\n",
    "example_words = [token for token in example_sentence if not token.is_punct]\n",
    "unique_words = set([token.text for token in example_words])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parts of Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOUN\n",
      "VERB\n"
     ]
    }
   ],
   "source": [
    "# homographs\n",
    "print(nlp(\"I need a break\")[3].pos_)\n",
    "print(nlp(\"I need to break the glass\")[3].pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parts of speech:\n",
      "There ADV\n",
      "was VERB\n",
      "nothing NOUN\n",
      "so ADP\n",
      "VERY PROPN\n",
      "remarkable ADJ\n",
      "in ADP\n",
      "that DET\n",
      "; PUNCT\n"
     ]
    }
   ],
   "source": [
    "# View the part of speech for some tokens in our sentence.\n",
    "print('\\nParts of speech:')\n",
    "for token in example_sentence[:9]:\n",
    "    print(token.orth_, token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies:\n",
      "There expl was\n",
      "was ROOT was\n",
      "nothing attr was\n",
      "so advmod remarkable\n",
      "VERY compound remarkable\n",
      "remarkable amod nothing\n",
      "in prep remarkable\n",
      "that pobj in\n",
      "; punct was\n"
     ]
    }
   ],
   "source": [
    "# Dependencies\n",
    "print('\\nDependencies:')\n",
    "for token in example_sentence[:9]:\n",
    "    print(token.orth_, token.dep_, token.head.orth_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERSON Alice\n",
      "PERSON Alice\n",
      "PERSON White Rabbit\n",
      "ORG VERY\n",
      "PERSON Alice\n",
      "ORG VERY\n",
      "PERSON Rabbit\n",
      "PERSON Rabbit\n",
      "EVENT WATCH\n",
      "ORG POCKET\n"
     ]
    }
   ],
   "source": [
    "# Entities\n",
    "# Extract the first ten entities.\n",
    "entities = list(alice_doc.ents)[0:10]\n",
    "for entity in entities:\n",
    "    print(entity.label_, ' '.join(t.orth_ for t in entity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Beau', 'Conqueror', 'Pat', 'Jack', 'Dodo', 'Cat', 'King', 'Soles', 'WILLIAM', 'Last', 'Tillie;', 'Curiouser', 'Longitude', 'Rabbit', 'Latitude', 'Cheshire Puss', 'Pepper', 'ONE', 'Morcar', 'Brandy', 'Tortoise', 'Lizard', 'Queen', 'Father William', 'Pigeon', 'Twinkle', 'Treacle', 'Mabel', 'ALICE', 'Edgar Atheling', 'Mouse', 'Duck', 'Mock Turtle', 'Alice', 'Eaglet', 'Dinn', 'Silence', 'Shakespeare', 'THAT', \"W. RABBIT'\", 'Ma', 'ALL', 'Footman', 'Seaography', 'Mary Ann', 'Beautiful', 'Majesty', 'Tut', 'Shy', 'THESE', \"Mary Ann!'\", 'Dormouse', 'THIS', 'Hush', 'Drawling', 'Dinah', 'WHAT', 'Ahem', 'Knave', 'ME', 'Lory', 'Mine', 'Idiot', 'O Mouse', 'Cheshire Cat', 'Gryphon', \"Rabbit's--'Pat\", 'Bill', 'Mock', 'Hjckrrh', 'Game', 'William', 'Begin', 'Soup', 'Hare', 'Tis', 'VOICE', 'Edwin', 'Prizes', 'then!--Bill', 'Hand', 'White Rabbit'}\n"
     ]
    }
   ],
   "source": [
    "# All of the uniqe entities spaCy thinks are people.\n",
    "people = [entity.text for entity in list(alice_doc.ents) if entity.label_ == \"PERSON\"]\n",
    "print(set(people))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
