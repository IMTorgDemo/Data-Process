{\rtf1\ansi\ansicpg1252\cocoartf1561\cocoasubrtf100
{\fonttbl\f0\fswiss\fcharset0 Helvetica;\f1\froman\fcharset0 Times-Roman;}
{\colortbl;\red255\green255\blue255;\red0\green0\blue233;\red0\green0\blue0;}
{\*\expandedcolortbl;;\cssrgb\c0\c0\c93333;\cssrgb\c0\c0\c0;}
{\*\listtable{\list\listtemplateid1\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid1\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid1}}
{\*\listoverridetable{\listoverride\listid1\listoverridecount0\ls1}}
\margl1440\margr1440\vieww17660\viewh19600\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\fs24 \cf0 # R Libraries with Specific Functionality\
\
\pard\pardeftab720\sl280\partightenfactor0

\f1 \cf2 \expnd0\expndtw0\kerning0
\ul \ulc2  \cf3 \ulnone \
# Maintained Libraries with Active Communities\
\
\pard\pardeftab720\sl280\partightenfactor0
{\field{\*\fldinst{HYPERLINK "https://cran.r-project.org/web/packages/textreuse/index.html"}}{\fldrslt \cf2 \ul textreuse}} provides a set of tools for measuring similarity among documents and helps with detecting passages which have been reused. The package implements shingled n-gram, skip n-gram, and other tokenizers; similarity/dissimilarity functions; pairwise comparisons; minhash and locality sensitive hashing algorithms; and a version of the Smith-Waterman local alignment algorithm suitable for natural language. \
https://github.com/ropensci/textreuse\
\pard\pardeftab720\sl280\partightenfactor0

\f0 \cf0 \kerning1\expnd0\expndtw0 \
\pard\pardeftab720\sl280\partightenfactor0
{\field{\*\fldinst{HYPERLINK "https://cran.r-project.org/web/packages/stringdist/index.html"}}{\fldrslt 
\f1 \cf2 \expnd0\expndtw0\kerning0
\ul stringdist}}
\f1 \cf3 \expnd0\expndtw0\kerning0
 implements an approximate string matching version of R's native 'match' function. It can calculate various string distances based on edits (Damerau-Levenshtein, Hamming, Levenshtein, optimal string alignment), qgrams (q-gram, cosine, jaccard distance) or heuristic metrics (Jaro, Jaro-Winkler). An implementation of soundex is provided as well. Distances can be computed between character vectors while taking proper care of encoding or between integer vectors representing generic sequences. \
https://github.com/markvanderloo/stringdist\
https://journal.r-project.org/archive/2014-1/loo.pdf\
\
\pard\pardeftab720\sl280\partightenfactor0
{\field{\*\fldinst{HYPERLINK "https://cran.r-project.org/web/packages/koRpus/index.html"}}{\fldrslt \cf2 \ul koRpus}} is a diverse collection of functions for automatic language detection, hyphenation, several indices of lexical diversity (e.g., type token ratio, HD-D/vocd-D, MTLD) and readability (e.g., Flesch, SMOG, LIX, Dale-Chall). See the {\field{\*\fldinst{HYPERLINK "http://reaktanz.de/?c=hacking&s=koRpus"}}{\fldrslt \cf2 \ul web page }}for more information.\
https://reaktanz.de/?c=hacking&s=koRpus\
https://github.com/unDocUMeantIt/koRpus\
https://ripley.psycho.hhu.de/koRpus/\
\
\pard\pardeftab720\sl280\partightenfactor0
{\field{\*\fldinst{HYPERLINK "https://cran.r-project.org/web/packages/alineR/index.html"}}{\fldrslt \cf2 \ul alineR}} helps calculate the phonetic distance between words (the 'ALINE' distance). The score is based on phonetic featuers represented with the Unicode-compliant International Phonetic Alphabet (IPA). Parameterized features weights are used to determine the optimal alignment and functions are provided to estimate optimum values using a genetic algorithm and supervised learning. \
https://journal.r-project.org/archive/2017/RJ-2017-005/index.html\
\pard\pardeftab720\partightenfactor0

\f0 \cf3 \outl0\strokewidth0 \strokec3 alineR: an R Package for Optimizing Feature-Weighted Alignments and Linguistic Distances
\fs68\fsmilli34438 \
\pard\pardeftab720\sl280\partightenfactor0

\fs24 \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 \
\pard\pardeftab720\partightenfactor0
{\field{\*\fldinst{HYPERLINK "https://cran.r-project.org/web/packages/languageR/index.html"}}{\fldrslt 
\f1 \cf2 \expnd0\expndtw0\kerning0
\ul languageR}}
\f1 \cf3 \expnd0\expndtw0\kerning0
 provides data sets and functions exemplifying statistical methods, and some facilitatory utility functions used in the book by R. H. Baayen\
\pard\pardeftab720\partightenfactor0

\f0 \cf3 \outl0\strokewidth0 \strokec3 Analyzing Linguistic Data: A practical introduction to statistics
\fs33\fsmilli16600 \
\pard\pardeftab720\sl280\partightenfactor0

\f1\fs24 \cf3 \outl0\strokewidth0 \
\pard\pardeftab720\sl280\partightenfactor0
{\field{\*\fldinst{HYPERLINK "https://cran.r-project.org/web/packages/zipfR/index.html"}}{\fldrslt \cf2 \ul zipfR}} offers some statistical models for word frequency distributions. The utilities include functions for loading, manipulating and visualizing word frequency data and vocabulary growth curves. The package also implements several statistical models for the distribution of word frequencies in a population. (The name of this library derives from the most famous word frequency distribution, Zipf's law.) \
http://zipfr.r-forge.r-project.org/\
\
\pard\pardeftab720\sl280\partightenfactor0
{\field{\*\fldinst{HYPERLINK "https://cran.r-project.org/web/packages/phonics/index.html"}}{\fldrslt \cf2 \ul phonics}} provides a collection of phonetic algorithms including Soundex, Metaphone, NYSIIS, Caverphone, and others. \
https://github.com/howardjp/phonics\
\
\pard\pardeftab720\sl280\partightenfactor0
{\field{\*\fldinst{HYPERLINK "https://cran.r-project.org/web/packages/stm/index.html"}}{\fldrslt \cf2 \ul stm}} (Structural Topic Model) implements a topic model derivate that can include document-level meta-data. The package also includes tools for model selection, visualization, and estimation of topic-covariate regressions. \
http://www.structuraltopicmodel.com/\
https://juliasilge.com/blog/sherlock-holmes-stm/\
\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sl280\partightenfactor0
\ls1\ilvl0{\field{\*\fldinst{HYPERLINK "https://cran.r-project.org/web/packages/qdap/index.html"}}{\fldrslt \cf2 \ul qdap}} helps with quantitative discourse analysis of transcripts. \
https://github.com/trinker/qdap\
http://trinker.github.io/qdap/vignettes/qdap_vignette.html\
\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sl280\partightenfactor0
\ls1\ilvl0{\field{\*\fldinst{HYPERLINK "https://cran.r-project.org/web/packages/quanteda/index.html"}}{\fldrslt \cf2 \ul quanteda}} supports quantitative analysis of textual data. \
https://tutorials.quanteda.io/\
\
\pard\pardeftab720\sl280\partightenfactor0
\cf3 \
\
\
\
# Older Libraries with Less-Active Community\
\
\pard\pardeftab720\sl280\partightenfactor0
{\field{\*\fldinst{HYPERLINK "https://cran.r-project.org/web/packages/lsa/index.html"}}{\fldrslt \cf2 \ul \ulc2 lsa}} provides routines for performing a latent semantic analysis with R. The basic idea of latent semantic analysis (LSA) is, that text do have a higher order (=latent semantic) structure which, however, is obscured by word usage (e.g. through the use of synonyms or polysemy). By using conceptual indices that are derived statistically via a truncated singular value decomposition (a two-mode factor analysis) over a given document-term matrix, this variability problem can be overcome. The article {\field{\*\fldinst{HYPERLINK "http://www.springerlink.com/content/g7u377132gq5623g/"}}{\fldrslt \cf2 \ul \ulc2 Investigating Unstructured Texts with Latent Semantic Analysis }}gives a detailed overview and demonstrates the use of the package with examples from the are of technology-enhanced learning. \
\
\pard\pardeftab720\sl280\partightenfactor0
{\field{\*\fldinst{HYPERLINK "https://cran.r-project.org/web/packages/lda/index.html"}}{\fldrslt \cf2 \ul \ulc2 lda}} implements Latent Dirichlet Allocation and related models similar to LSA and topicmodels. \
\
\pard\pardeftab720\sl280\partightenfactor0
{\field{\*\fldinst{HYPERLINK "https://cran.r-project.org/web/packages/kernlab/index.html"}}{\fldrslt \cf2 \ul \ulc2 kernlab}} allows to create and compute with string kernels, like full string, spectrum, or bounded range string kernels. It can directly use the document format used by {\field{\*\fldinst{HYPERLINK "https://cran.r-project.org/web/packages/tm/index.html"}}{\fldrslt \cf2 \ul \ulc2 tm}} as input. \
\
\pard\pardeftab720\sl280\partightenfactor0
{\field{\*\fldinst{HYPERLINK "https://cran.r-project.org/web/packages/RTextTools/index.html"}}{\fldrslt \cf2 \ul \ulc2 RTextTools}} is a machine learning package for automatic text classification. It implements the nine different algorithms (svm, slda, boosting, bagging, rf, glmnet, tree, nnet, and maxent) and routines supporting the evaluation of accuracy. \
\
\
\
\
# Deprecated Libraries\
\
\pard\pardeftab720\sl280\partightenfactor0
{\field{\*\fldinst{HYPERLINK "https://cran.r-project.org/web/packages/RKEA/index.html"}}{\fldrslt \cf2 \ul \ulc2 RKEA}} provides an R interface to {\field{\*\fldinst{HYPERLINK "http://www.nzdl.org/Kea/"}}{\fldrslt \cf2 \ul \ulc2 KEA }}(Version 5.0). KEA (for Keyphrase Extraction Algorithm) allows for extracting keyphrases from text documents.\
https://code.google.com/archive/p/kea-algorithm/downloads\
\
\
\
\
END}