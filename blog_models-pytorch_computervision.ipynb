{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision Using PyTorch\n",
    "Date: 2020-07-02  \n",
    "Author: Jason Beach  \n",
    "Categories: Cheatsheet, Data_Science  \n",
    "Tags: pytorch, python, classification  \n",
    "<!--eofm-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The deep learning movement began by applying neural networks to image classification.  PyTorch became a leading framework for work in this field.  This post provides a cheatsheet to some of the basic methods used for computer vision, using PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "This is a typical environment setup.  Seed the Random Number Generator for all devices (both CPU and CUDA) using `manual_seed()` so that work can be reproduced.  Computations are deterministic only on your specific problem, platform, and PyTorch release.  See, [here](https://pytorch.org/docs/stable/notes/randomness.html), for more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f7dc265b930>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "torch.set_printoptions(edgeitems=2)\n",
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Popular datasets include: MNIST, FashionMNIST, CIFAR-100, SVHN, Coco, Omniglot.  The `torchvision` library has access to them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cfd6b87ca374bfc8716eb179a067aa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/cifar-10-python.tar.gz to data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets\n",
    "\n",
    "cifar10 = datasets.CIFAR10('data', train=True, download=True)\n",
    "cifar10_val = datasets.CIFAR10('data', train=False, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torchvision.datasets.cifar.CIFAR10,\n",
       " torchvision.datasets.vision.VisionDataset,\n",
       " torch.utils.data.dataset.Dataset,\n",
       " object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(cifar10).__mro__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<PIL.Image.Image image mode=RGB size=32x32 at 0x7F7DC113E358>,\n",
       " 1,\n",
       " 'automobile')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = ['airplane','automobile','bird','cat','deer',\n",
    "               'dog','frog','horse','ship','truck']\n",
    "len(cifar10)                      #items in dataset\n",
    "img, label = cifar10[99]     \n",
    "img, label, class_names[label]    #image, label, label-name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform Pipelines\n",
    "\n",
    "The following transforms are used in nearly every pipeline to prepare data for a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CenterCrop', 'ColorJitter', 'Compose', 'FiveCrop', 'Grayscale', 'Lambda', 'LinearTransformation', 'Normalize', 'Pad', 'RandomAffine', 'RandomApply', 'RandomChoice', 'RandomCrop', 'RandomErasing', 'RandomGrayscale', 'RandomHorizontalFlip', 'RandomOrder', 'RandomPerspective', 'RandomResizedCrop', 'RandomRotation']\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "print(dir(transforms)[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_tensor = transforms.ToTensor()\n",
    "img_t = to_tensor(img)\n",
    "img_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_cifar10 = datasets.CIFAR10('data', train=True, download=False,\n",
    "                                  transform=transforms.ToTensor()\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original PIL image ranged from 0 to 255 (8-bit per channel), the ToTensor transform turned the data into 32-bit floating point per channel, scaling values down from 0.0 to 1.0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.), tensor(1.))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_t.min(), img_t.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Must use permute to change the order of the axes from CxHxW to HxWxC to match what Matplotlib expects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img_t.permute(1, 2, 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize()\n",
    "\n",
    "Unfortunately, some manual work must be done to obtain the mean and stadard deviations used to normalize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 32, 32, 50000])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.2470, 0.2435, 0.2616])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs = torch.stack([img_t for img_t, _ in tensor_cifar10], dim=3)    #stack all tensors returned by the dataset along an extra dimension\n",
    "print( imgs.shape )\n",
    "\n",
    "imgs.view(3, -1).mean(dim=1)   #mean per channel\n",
    "imgs.view(3, -1).std(dim=1)    #std per channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms.Normalize((0.4915, 0.4823, 0.4468), (0.2470, 0.2435, 0.2616))\n",
    "cifar10 = datasets.CIFAR10('data', train=True, download=False,\n",
    "                          transform=transforms.Compose([\n",
    "                              transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                                                   (0.2470, 0.2435, 0.2616))\n",
    "                          ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_val = datasets.CIFAR10('data', train=False, download=False,\n",
    "                          transform=transforms.Compose([\n",
    "                              transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                                                   (0.2470, 0.2435, 0.2616))\n",
    "                          ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is because normalization has shifted the RGB levels outside the 0.0 to 1.0 range and changed the overall magnitudes of the channels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_t, _ = cifar10[99]\n",
    "plt.imshow(img_t.permute(1, 2, 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully-Connected, Feed-Forward Network\n",
    "\n",
    "This is the most simple type of neural network.  We can use the `nn.Sequential` function to step through each layer of the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem statement\n",
    "\n",
    "Within the cifar10 dataset, we are only looking at items labelled 'birds' or 'planes'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {0: 0, 2: 1}\n",
    "cifar2 = [(img, label_map[label]) for img, label in cifar10 if label in [0, 2]]\n",
    "cifar2_val = [(img, label_map[label]) for img, label in cifar10_val if label in [0, 2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Softmax is a monotone function, in that lower values in the input will correspond to lower values in the output.  However, it’s not \"scale invariant\", in that the ratio between values is not preserved. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0900, 0.2447, 0.6652])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1.0, 2.0, 3.0])\n",
    "softmax = torch.nn.Softmax(dim=0)\n",
    "softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "model = nn.Sequential(\n",
    "            nn.Linear(3072, 512),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(512, 2),\n",
    "            nn.Softmax(dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test design\n",
    "\n",
    "Once a model is designed, it should be tested with the same input to ensure no problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img, _ = cifar2[0]\n",
    "plt.imshow(img.permute(1, 2, 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elements are initialized randomly by PyTorch between -1.0 and 1.0, so don't be confused by the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3700, 0.6300]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_batch = img.view(-1).unsqueeze(0)\n",
    "out = model(img_batch)                  \n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss function associates a meaning to these two numbers, after back-propagation. If the labels are provided as index 0 for \"airplane\" and index 1 for \"bird\", than that’s the order the outputs will be induced to take. Therefore, after training we will be able to get the label as an index by computing the argmax of the output probabilities, that is, the index at which we get the maximum probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, index = torch.max(out, dim=1)\n",
    "index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want a loss function that is very high when the likelihood is low, that is, so low that the alternatives have a higher probability. Negative log likelihood (NLL) is a good candidate as it takes probabilities in input, so as the likelihood grows the other probabilities will necessarily decrease.  It has the expression: \n",
    "\n",
    "`NLL = - sum(log(out_i[c_i]))`, where the sum is taken over `N` samples and `c_i` is the correct class for sample `i`.\n",
    "\n",
    "The `nn.NLLLoss` doesn’t take a logarithm of the likelihood, but it expects a tensor of log probabilities in input.  This is because taking a logarithm around 0 can create some VERY small numbers.  So, we must use `nn.LogSoftmax` instead of `nn.Softmax`, which takes care to make the calculation numerically stable. \n",
    "\n",
    "The combination of `nn.LogSoftmax` and `nn.NLLLoss` is equivalent to using `nn.CrossEntropyLoss`. In fact, the combined mathematical expression for taking the negative sum of log softmax of a vector of values corresponds to the mathematical expression for cross entropy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax:  tensor([[-inf, 0.]])\n",
      "log softmax:  tensor([[0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim=1)\n",
    "log_softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "x = torch.tensor([[0.0, 104.0]])\n",
    "softmax(x)\n",
    "print('softmax: ', torch.log(softmax(x)) )\n",
    "print('log softmax: ', torch.exp(log_softmax(x)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "model = nn.Sequential(\n",
    "            nn.Linear(3072, 512),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(512, 2),\n",
    "            nn.LogSoftmax(dim=1))    #instead of nn.Softmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7372, -0.6509]], grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_batch = img.view(-1).unsqueeze(0)\n",
    "out = model(img_batch)                  \n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss takes the output of nn.LogSoftmax for a batch as the first argument and a tensor of class indices (0’s and 1’s in our case) as the second argument. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6509, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = nn.NLLLoss()\n",
    "out = model(img.view(-1).unsqueeze(0))\n",
    "loss(out, torch.tensor([label]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model\n",
    "\n",
    "How we use records in training has important consequences.  An epoch ends when all samples in the training set have been evaluated.  But, this could be done in multiple ways: \n",
    "i) using ever observation in the dataset, then update the gradient (all obs)\n",
    "ii) using ever observation in the dataset, and updating the gradient on each sample, or\n",
    "iii) dividing the dataset into minibatches, for every minibatch, for every obs in minibatch, then update the gradient (all obs in minibatch)\n",
    "\n",
    "By shuffling samples at each epoch and estimating the gradient on one or (preferably, for stability) a few samples at a time, we are effectively introducing randomness in our gradient descent. Remember SGD? It stands for Stochastic Gradient Descent, and this is what the S is about: working on small batches (aka minibatches) of shuffled data.  Using minibatches helps convergence and prevents the optimization process from getting stuck in local minima it encounters along the way.\n",
    "\n",
    "Size of minibatches is another hyperparameter.  The job of a `torch.utils.data.DataLoader` is to sample minibatches from a Dataset, giving the flexibility to choose from different sampling strategies, a very common one being uniform sampling after shuffling the data at each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Training loss 0.5787188410758972\n",
      "Epoch 1, Training loss 0.6271973848342896\n",
      "Epoch 10, Training loss 0.19447796046733856\n",
      "Epoch 20, Training loss 0.4353618323802948\n",
      "Epoch 30, Training loss 0.17823220789432526\n",
      "Epoch 40, Training loss 0.13526563346385956\n",
      "Epoch 50, Training loss 0.09489273279905319\n",
      "Epoch 60, Training loss 0.02850762940943241\n",
      "Epoch 70, Training loss 0.01548031810671091\n",
      "Epoch 80, Training loss 0.00986947026103735\n",
      "Epoch 90, Training loss 0.009175573475658894\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64, shuffle=True)\n",
    "\n",
    "model = nn.Sequential(\n",
    "            nn.Linear(3072, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 2),\n",
    "            nn.LogSoftmax(dim=1))\n",
    "\n",
    "learning_rate = 1e-2\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.NLLLoss()\n",
    "n_epochs = 100\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for imgs, labels in train_loader:\n",
    "        #imgs will be a tensor of size 64x3x32x32\n",
    "        #labels a tensor of size 64 containing label indices\n",
    "        outputs = model(imgs.view(imgs.shape[0], -1))\n",
    "        loss = loss_fn(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if epoch == 1 or epoch % 10 == 0:\n",
    "        print('Epoch {}, Training loss {}'.format(\n",
    "            epoch, float(loss)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.998200\n"
     ]
    }
   ],
   "source": [
    "#training set\n",
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64, shuffle=False)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in train_loader:\n",
    "        outputs = model(imgs.view(imgs.shape[0], -1))\n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "        total += labels.shape[0]\n",
    "        correct += int((predicted == labels).sum())\n",
    "        \n",
    "print(\"Accuracy: %f\" % (correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.820000\n"
     ]
    }
   ],
   "source": [
    "#validation set\n",
    "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=64, shuffle=False)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in val_loader:\n",
    "        outputs = model(imgs.view(imgs.shape[0], -1))\n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "        total += labels.shape[0]\n",
    "        correct += int((predicted == labels).sum())\n",
    "        \n",
    "print(\"Accuracy: %f\" % (correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "High training accuracy with low test accuracy probably means over-fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(393602, [393216, 128, 256, 2])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numel_list = [p.numel() for p in model.parameters() if p.requires_grad == True]\n",
    "sum(numel_list), numel_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The combination of nn.LogSoftmax and nn.NLLLoss is equivalent to using nn.CrossEntropyLoss.  The only gotcha that the output of our model will not be interpretable as probabilities (or log probabilities). We’ll need to explicitly pass the output through a softmax to obtain those. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "connected_model = nn.Sequential(\n",
    "            nn.Linear(3072, 1024),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 2))\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3737474, [3145728, 1024, 524288, 512, 65536, 128, 256, 2])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numel_list = [p.numel() for p in connected_model.parameters() if p.requires_grad == True]\n",
    "sum(numel_list), numel_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Network\n",
    "\n",
    "Computer vision techniques are dominated by convolutional neural networks because of their accuracy in image classification. The technique of image analysis and recognition, where the agriculture and weather features are extracted from the open-source satellites like LSAT to predict the future growth and yield of a particular land are being implemented.  With convolutions we achieve: locality and translation-invariance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with the convolution\n",
    "\n",
    "Here, we have a convolution layer: 3 input channels, 16 (arbitrary) output channgels, and 3x3, 2-dim kernel.  Expect a weight tensor sized the following way: we’ll have as many kernels, sized (n_input_channels)x3x3, as the number of output channels. That is, we expect the weight tensor to be sized (n_input_channels)x3x3x(n_output_channels), so 3x3x3x16. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 3, 3, 3]), torch.Size([16]))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv = nn.Conv2d(3, 16, kernel_size=3)\n",
    "conv.weight.shape, conv.bias.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, PyTorch will skip pixels at the boundary, thereby producing images that are one half of the convolution kernel width (in our case, 3//2 = 1) smaller on each side. This explains why we’re missing two pixels in each dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 3, 32, 32]), torch.Size([1, 16, 30, 30]))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img, _ = cifar2[0]\n",
    "output = conv(img.unsqueeze(0))     #unsqueeze accounts for batch dimension\n",
    "img.unsqueeze(0).shape, output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(output[0, 0].detach(), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we are using padding of 1 on the borders.  The size of weight and bias don’t change whether padding is used or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 3, 32, 32]), torch.Size([1, 1, 32, 32]))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv = nn.Conv2d(3, 1, kernel_size=3, padding=1)\n",
    "output = conv(img.unsqueeze(0))\n",
    "img.unsqueeze(0).shape, output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local average \n",
    "\n",
    "Blurring occurs because every pixel of the output is the average of a neighborhood of the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    conv.bias.zero_()\n",
    "with torch.no_grad():\n",
    "    conv.weight.fill_(1.0 / 9.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "output = conv(img.unsqueeze(0))\n",
    "plt.imshow(output[0, 0].detach(), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edge detection\n",
    "\n",
    "Edge detection kernel: the kernel highlights the vertical edge between two horizontally adjacent regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = nn.Conv2d(3, 1, kernel_size=3, padding=1)\n",
    "with torch.no_grad():\n",
    "    conv.weight[:] = torch.tensor([[-1.0, 0.0, 1.0],\n",
    "                                   [-1.0, 0.0, 1.0],\n",
    "                                   [-1.0, 0.0, 1.0]])\n",
    "conv.bias.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this angle, the job of a convolutional neural network is to estimate the kernel of a set of filter banks in successive layers, that will transform a multi-channel image into another multi-channel image, where different channels will correspond to different features (e.g. one channel for the average, another channel for vertical edges, etc)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooling\n",
    "\n",
    "Downsampling could in principle occur in different ways. Scaling an image by a half is the equivalent of taking 4 neighboring pixels in input and producing one pixel in output. How we compute the value of the output based on the values of the input is up to us. We could:\n",
    "\n",
    "* Average the four pixels. This was a common approach early on, but has since fallen out of favor somewhat.\n",
    "* Take the maximum of the four pixels (__Max Pooling__). This is currently the most commonly used approach, but has a downside of discarding the other 3/4ths of the data.\n",
    "* Perform a strided convolution, where only every Nth pixel is calculated. A 3x4 convolution with stride 2 still incorporates input from all pixels from the previous layer. Current literature shows promise for this approach, but it has not yet supplanted maxpool.\n",
    "\n",
    "Max-pooling is provided by the `nn.MaxPool2d` module.  It takes in input the size of the neighborhood over which to operate the pooling operation. If we wish to downsample our image by a half, we’ll want to use a size of 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 3, 32, 32]), torch.Size([1, 3, 16, 16]))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool = nn.MaxPool2d(2)\n",
    "output = pool(img.unsqueeze(0))\n",
    "img.unsqueeze(0).shape, output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model\n",
    "\n",
    "While using `nn.Sequential` may seem convenient, it is only capable for the most basic networks.  In order to make detailed modifications, we will have to create our own `nn.Module` subclasses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18090"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
    "            nn.Tanh(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(16, 8, kernel_size=3, padding=1),\n",
    "            nn.Tanh(),\n",
    "            nn.MaxPool2d(2),\n",
    "            # WARNING: something missing here\n",
    "            nn.Linear(512, 32),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(32, 2))\n",
    "\n",
    "sum([p.numel() for p in model.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This fails\n",
    "model(img.unsqueeze(0))\n",
    "#RuntimeError: size mismatch, m1: [64 x 8], m2: [512 x 32] at c:\\...\\THTensorMath.cpp:940"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking back at the model the only module that has to have a 512 x 32 tensor is `nn.Linear(512, 32)`, the first linear module after the last convolution block.  What’s missing there is the reshaping step from a 8-channel 8x8 image to a 512-element, 1D vector (1D if we ignore the batch dimension, that is). This could be achieved by calling view on the output of the last `nn.MaxPool2d`, but unfortunately we don’t have any explicit visibility of the output of each module when we use `nn.Sequential`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Net class is equivalent to the `nn.Sequential` model we built above in terms of submodules, but, by writing the forward function explicitly, we were able to manipulate the output of `self.pool3` directly and call view on it to turn it into a BxN vector. Note that we leave the batch dimension as -1 in the call to view, since in principle we don’t know how many samples there’ll be in the batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()    \n",
    "        #no matter how nested the submodule, any nn.Module can access the list of all child parameters. \n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.act1 = nn.Tanh()\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
    "        self.act2 = nn.Tanh()\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.fc1 = nn.Linear(8 * 8 * 8, 32)\n",
    "        self.act4 = nn.Tanh()\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.pool1(self.act1(self.conv1(x)))\n",
    "        out = self.pool2(self.act2(self.conv2(out)))\n",
    "        out = out.view(-1, 8 * 8 * 8)      #<<<<<new\n",
    "        out = self.act4(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18090"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net()\n",
    "\n",
    "sum([p.numel() for p in model.parameters()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears a bit of a waste to register submodules that have no parameters, like `nn.Tanh` and `nn.MaxPool2d`. It would be easier to call them directly in the forward function.\n",
    "\n",
    "It makes sense to keep using `nn` modules for `nn.Linear` and `nn.Conv2d`, so that Net will be able to manage their `Parameter`s (state) during training. However, we can safely switch to the functional counterparts of pooling and activation, since they have no parameters.\n",
    "\n",
    "One may want to still initialize `nn.MaxPool2d` as we did before, to reinforce the fact that we’re using a kernel of 2. We could actually have just one instance of `nn.MaxPool2d` that we use everwhere - since `nn.MaxPool2d` has no parameters, `self.pool1`, `self.pool2` and `self.pool3` we initialized earlier were essentially the same thing and could be used interchangeably.\n",
    "\n",
    "In more complex models getting the size of the first linear layer right is sometimes a source of frustration.  Creating a submodule can be helpful. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(8 * 8 * 8, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.tanh(self.conv1(x)), 2)\n",
    "        out = F.max_pool2d(torch.tanh(self.conv2(out)), 2)\n",
    "        out = out.view(-1, 8 * 8 * 8)\n",
    "        out = torch.tanh(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1432, 0.1911]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net()\n",
    "model(img.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Training loss 0.7593254446983337\n",
      "Epoch 1, Training loss 0.40714699029922485\n",
      "Epoch 10, Training loss 0.18846207857131958\n",
      "Epoch 20, Training loss 0.08485838770866394\n",
      "Epoch 30, Training loss 0.31306666135787964\n",
      "Epoch 40, Training loss 0.25074532628059387\n",
      "Epoch 50, Training loss 0.19872312247753143\n",
      "Epoch 60, Training loss 0.08163115382194519\n",
      "Epoch 70, Training loss 0.14351972937583923\n",
      "Epoch 80, Training loss 0.1487308293581009\n",
      "Epoch 90, Training loss 0.37778040766716003\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64, shuffle=True)\n",
    "    \n",
    "model = Net()\n",
    "learning_rate = 1e-2\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "n_epochs = 100\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for imgs, labels in train_loader:\n",
    "        outputs = model(imgs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "                \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if epoch == 1 or epoch % 10 == 0:\n",
    "        print('Epoch {}, Training loss {}'.format(\n",
    "            epoch, float(loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.890500\n"
     ]
    }
   ],
   "source": [
    "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=64, shuffle=False)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in val_loader:\n",
    "        outputs = model(imgs)\n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "        total += labels.shape[0]\n",
    "        correct += int((predicted == labels).sum())\n",
    "        \n",
    "print(\"Accuracy: %f\" % (correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This only saves the parameters.  So you must ensure the model (submodule) definition is not changed when instantiating and loading the parameters (state)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), data_path + 'birds_vs_airplanes.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = Net()\n",
    "loaded_model.load_state_dict(torch.load(data_path + 'birds_vs_airplanes.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modifying Network Designs\n",
    "\n",
    "We are interested in changing the details of the network, such as width (neurons) and depth (layers), as well as adding some nice features to reduce overfitting, such as:\n",
    "\n",
    "_width_\n",
    "\n",
    "* adaptive learning rate\n",
    "* stopping criteria\n",
    "* regularization: l1 (manual), l2 (`weight_decay`)\n",
    "* dropout: `nn.Dropout*D`\n",
    "* principled augmentation: `nn.BatchNorm*D`\n",
    "\n",
    "_depth_\n",
    "\n",
    "* skip connection: ResNet()\n",
    "* identity mapping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(8 * 8 * 8, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.relu(self.conv1(x)), 2)\n",
    "        out = F.max_pool2d(torch.relu(self.conv2(out)), 2)\n",
    "        out = out.view(-1, 8 * 8 * 8)\n",
    "        out = torch.tanh(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, width=16):\n",
    "        super(Net, self).__init__()\n",
    "        self.width = width\n",
    "        self.conv1 = nn.Conv2d(3, self.width, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(self.width, int(self.width/2), kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(8 * 8 * int(self.width/2), int(self.width*2))\n",
    "        self.fc2 = nn.Linear(int(self.width*2), 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.relu(self.conv1(x)), 2)\n",
    "        out = F.max_pool2d(torch.relu(self.conv2(out)), 2)\n",
    "        out = out.view(-1, 8 * 8 * int(self.width/2))\n",
    "        out = torch.tanh(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1477, -0.0117]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net(width=64)\n",
    "model(img.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Training loss 0.5520237684249878\n",
      "Epoch 1, Training loss 0.31745433807373047\n",
      "Epoch 10, Training loss 0.10780216008424759\n",
      "Epoch 20, Training loss 0.12875433266162872\n",
      "Epoch 30, Training loss 0.0402236171066761\n",
      "Epoch 40, Training loss 0.003839320968836546\n",
      "Epoch 50, Training loss 0.0046023111790418625\n",
      "Epoch 60, Training loss 0.6562945246696472\n",
      "Epoch 70, Training loss 0.0052324621938169\n",
      "Epoch 80, Training loss 0.2878885567188263\n",
      "Epoch 90, Training loss 0.005372203420847654\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64, shuffle=True)\n",
    "    \n",
    "model = Net(width=32)\n",
    "learning_rate = 1e-1\n",
    "weight_decay=0.001\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "n_epochs = 100\n",
    "stopping_criteria = 1e-05\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for imgs, labels in train_loader:\n",
    "        outputs = model(imgs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        \n",
    "        #l1\n",
    "        #l1_lambda = 0.9\n",
    "        #regularization_loss = 0\n",
    "        #for param in model.parameters(): \n",
    "        #    regularization_loss += torch.sum(abs(param))\n",
    "        #l1_norm = sum(abs(p) for p in model.parameters())\n",
    "        #loss = loss + l1_lambda * regularization_loss\n",
    "\n",
    "        #l2\n",
    "        #optimizer = torch.optim.SGD(model.parameters(), lr=0.01, weight_decay=0.001)\n",
    "        #(or)\n",
    "        #l2_lambda = 0.001\n",
    "        #l2_norm = sum(p.pow(2.0).sum() for p in model.parameters())\n",
    "        #loss = loss + l2_lambda * l2_norm\n",
    "                \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if epoch == 1 or epoch % 10 == 0:\n",
    "        print('Epoch {}, Training loss {}'.format(\n",
    "            epoch, float(loss)))\n",
    "    if float(loss) < stopping_criteria:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For modules that are only used during training, such as `nn.Dropout`, PyTorch lets us switch between the two modalities by calling `model.train()` or `model.eval()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.912500\n"
     ]
    }
   ],
   "source": [
    "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=64, shuffle=False)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in val_loader:\n",
    "        model.eval()\n",
    "        outputs = model(imgs)\n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "        total += labels.shape[0]\n",
    "        correct += int((predicted == labels).sum())\n",
    "        \n",
    "print(\"Accuracy: %f\" % (correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This post can be a cheatsheet for basic neural network designs, such as the Feed Forward and Convolution Network."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
